name: ğŸ¤– Daily Scholarship Crawler

on:
  # ë§¤ì¼ ë°¤ 12ì‹œ (í•œêµ­ì‹œê°„ ê¸°ì¤€)
  schedule:
    - cron: '0 15 * * *'  # UTC 15:00 = KST 00:00
  
  # ìˆ˜ë™ ì‹¤í–‰ë„ ê°€ëŠ¥í•˜ê²Œ
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest
    
    steps:
      # 1. ì½”ë“œ ì²´í¬ì•„ì›ƒ
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4
      
      # 2. Python í™˜ê²½ ì„¤ì •
      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      # 3. ì˜ì¡´ì„± ì„¤ì¹˜
      - name: ğŸ“¦ Install dependencies
        run: |
          cd crawler
          pip install --upgrade pip
          pip install -r requirements.txt
      
      # 4. í¬ë¡¤ë§ ì‹¤í–‰
      - name: ğŸ•·ï¸ Run crawler
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          TARGET_URL: ${{ secrets.TARGET_URL }}
          BASE_DOMAIN: ${{ secrets.BASE_DOMAIN }}
          MAX_ITEMS: 50
          DELAY_SECONDS: 3
        run: |
          cd crawler
          python main.py
      
      # 5. ê²°ê³¼ ì•Œë¦¼ (ì„ íƒì‚¬í•­)
      - name: ğŸ“Š Crawling completed
        if: success()
        run: |
          echo "âœ… í¬ë¡¤ë§ ì„±ê³µ!"
          echo "$(date '+%Y-%m-%d %H:%M:%S') - Daily crawling completed"
      
      # 6. ì—ëŸ¬ ì•Œë¦¼ (ì„ íƒì‚¬í•­)
      - name: âŒ Crawling failed
        if: failure()
        run: |
          echo "âŒ í¬ë¡¤ë§ ì‹¤íŒ¨!"
          echo "$(date '+%Y-%m-%d %H:%M:%S') - Daily crawling failed"

