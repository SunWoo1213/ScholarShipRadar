name: ğŸ”§ Manual Crawler (On Demand)

on:
  # ìˆ˜ë™ ì‹¤í–‰ ì „ìš© (ë²„íŠ¼ í´ë¦­ìœ¼ë¡œ ì‹¤í–‰)
  workflow_dispatch:
    inputs:
      max_items:
        description: 'í¬ë¡¤ë§í•  ìµœëŒ€ ê³µê³  ìˆ˜'
        required: false
        default: '50'
        type: string
      delay_seconds:
        description: 'ìš”ì²­ ê°„ ë”œë ˆì´ (ì´ˆ)'
        required: false
        default: '3'
        type: string

jobs:
  manual-crawl:
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4
      
      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: ğŸ“¦ Install dependencies
        run: |
          cd crawler
          pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: ğŸ•·ï¸ Run manual crawler
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          TARGET_URL: ${{ secrets.TARGET_URL }}
          BASE_DOMAIN: ${{ secrets.BASE_DOMAIN }}
          MAX_ITEMS: ${{ github.event.inputs.max_items }}
          DELAY_SECONDS: ${{ github.event.inputs.delay_seconds }}
        run: |
          cd crawler
          echo "ğŸš€ ìˆ˜ë™ í¬ë¡¤ë§ ì‹œì‘..."
          echo "  - ìµœëŒ€ ê³µê³  ìˆ˜: $MAX_ITEMS"
          echo "  - ë”œë ˆì´: $DELAY_SECONDSì´ˆ"
          python main.py
      
      - name: âœ… Success notification
        if: success()
        run: |
          echo "âœ… ìˆ˜ë™ í¬ë¡¤ë§ ì™„ë£Œ!"
          echo "ì²˜ë¦¬ ì‹œê°„: $(date '+%Y-%m-%d %H:%M:%S')"

